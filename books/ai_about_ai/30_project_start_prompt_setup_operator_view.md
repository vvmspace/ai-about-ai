# Project-Start Prompt Setup (Operator View)

Most projects do not fail in month six.
They fail in week one,
when everyone had believed they were solving the same problem.

A solid **project-start prompt setup** is not decoration.
It is operating discipline.
If you shape it properly on day one,
you remove half the avoidable friction before it appears.

## The operator's brief

From an operator’s perspective, prompt setup has one job:
turn ambiguity into a manageable system.

Three outcomes matter:

- predictable output quality,
- controllable operational risk,
- measurable cost per useful result.

If a setup is “creative” but not measurable,
it is theatre.

## Build a start packet before first generation

Before any sprint, write and freeze a compact start packet.

1. **Mission brief** — exact outcome, user segment, and delivery window.
2. **Constraints ledger** — legal, technical, policy, brand limits.
3. **Reference canon** — source hierarchy, trust levels, and stale-source rules.
4. **Output schema** — what “done” looks like in practical terms.
5. **Evaluation rubric** — pass/fail signals with clear thresholds.

No packet, no sprint.
For the avoidance of doubt,
that boundary prevents expensive improvisation.

## Declare environment reality early

Many teams had lost days because no one wrote the operating assumptions.
Do it up front.

State explicitly:

- stack and version constraints,
- deployment environment,
- budget envelope,
- allowed tools and APIs,
- excluded dependencies,
- security and data handling limits.

If assumptions remain implicit,
incident tickets will clarify them later — at a higher price.

## Use a three-layer prompt architecture

Keep structure simple and enforceable.

- **System layer**: role, tone boundaries, hard safety rules.
- **Task layer**: immediate objective and acceptance criteria.
- **State layer**: prior decisions, unresolved questions, and context deltas.

Lock the system layer.
Version task and state daily.
Archive changes so regressions can be explained,
not guessed.

## Review prompts, not just outputs

Most teams inspect outputs.
High-performing teams inspect the prompt assets that produced them.

Add two preflight checks:

- **ambiguity score** — how many plausible interpretations remain,
- **dependency score** — how many fragile external facts can break the answer.

If either score is high,
refine prompt design before scaling workload.
That seems boring.
It is also how reliable teams stay reliable.

## Incident-resistant defaults

Calm defaults reduce downstream clean-up:

- require citations for factual claims,
- force explicit uncertainty markers,
- refuse unsupported legal/medical/financial certainty,
- escalate when constraints collide,
- log assumption changes with timestamps.

These defaults convert “confident nonsense”
into visible, manageable risk.

## A practical 15-minute launch check

Run this sequence before first delivery:

- Mission, user, and deadline are written.
- Constraints ledger is complete and current.
- Output schema and rubric are linked to the task.
- Source hierarchy is explicit.
- Escalation triggers are visible.
- One dry run is scored by rubric.

Then ship.
Not earlier.

## Operational takeaway

At project start,
prompt setup is **control-surface engineering** for an AI workflow.

Do it once with discipline,
and execution becomes calmer,
faster,
and much less dependent on luck.
