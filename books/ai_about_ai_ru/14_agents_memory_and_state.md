# Память, состояние и длинные задачи

Поисковый ключ: **память, состояние и длинные задачи**

Большинство агентных систем проваливает длинные задачи не потому, что модель «недостаточно умная».
Они проваливаются, потому что память ведётся как ведро.

Всё подряд добавляется.
Ничего не чистится.
Сигнал растворяется.
Потом система ведёт себя «странно».

Это не странность.
Это энтропия состояния.

## Память — это инфраструктура

Если агент работает часами, днями, неделями,
управление состоянием становится центральной архитектурой.

Нужны явные правила:

- что сохраняем,
- где сохраняем,
- сколько этому доверяем,
- когда обновляем,
- кто может исправлять.

Иначе длинные задачи превращаются в длинные галлюцинации.

## Трёхуровневая модель памяти

Практичная схема:

### 1) Working memory
Текущий контекст, эфемерный, агрессивно очищаемый.

### 2) Episodic memory
Недавние решения, действия и результаты.
Нужна для continuity и отладки.

### 3) Durable memory
Проверенные факты и устойчивые предпочтения.
Обновляется только через валидацию.

Ключевое правило: непроверенные утверждения не попадают в durable memory.

## Схема состояния лучше свободных заметок

Для повторяемых процессов используйте структурные поля:

- objective,
- текущий этап,
- выполненные действия,
- открытые вопросы,
- блокеры,
- следующий владелец,
- confidence,
- timestamp последней валидации.

Схема даёт наблюдаемость.
Наблюдаемость даёт восстановимость.

## Checkpoint для длинных задач

Задайте checkpoints по времени или этапам.
На checkpoint:

- суммируйте прогресс,
- архивируйте низкоценные детали,
- перепроверяйте незакрытые решения,
- обновляйте рискованные допущения,
- назначайте владельца следующего шага.

Так вы предотвращаете раздувание контекста и дрейф.

## Политики свежести памяти

Память стареет с разной скоростью.

- policy-факты могут требовать мгновенной инвалидизации,
- пользовательские предпочтения живут дольше,
- операционные метрики часто требуют скользящего окна.

Задайте TTL по типам памяти.
Истёкшая память должна требовать ревалидацию, а не использоваться молча.

## Полевой кейс: multi-day incident assistant

SRE-команда использовала агента для многодневных инцидентов.
Ранняя версия просто добавляла всё в историю.

Ко второму дню:
- повторяющиеся гипотезы,
- устаревшие допущения,
- путаница с владельцами действий.

Ввели структурную episodic memory и checkpoint каждые 4 часа.

Результат:
- чище handoff,
- меньше повторного анализа,
- легче смена дежурств.

Качество выросло из-за state hygiene, а не из-за замены модели.

## Антипаттерны

### 1) Бесконечная память «сама всё решит»
Считать, что большой context window отменяет state-дизайн.

### 2) Загрязнение durable memory
Сохранять low-confidence выводы как факты.

### 3) Нет механизма коррекции
Человек видит ошибку, но не может правильно обновить память.

### 4) Память без provenance
Факты хранятся без источника и времени проверки.

## Практика: дисциплина состояния для одного агента

Для одного long-running агента:

1. Введите 3 уровня памяти.
2. Задайте state-схему полей.
3. Установите TTL-политики.
4. Добавьте checkpoint summary каждые N шагов.
5. Дайте интерфейс ручной коррекции.

Через две недели измерьте:
- частоту повторных ошибок,
- путаницу на handoff,
- динамику token consumption.

## Стратегический вывод

Дизайн памяти определяет, станет ли агент надёжным коллегой или останется помощником одной сессии.

Короткие сессии вознаграждают clever prompting.
Длинная операционка вознаграждает state architecture.

Если цель — реальный рычаг в процессах,
state engineering обязателен.

Фраза, которую стоит держать рядом:

**Агенты масштабируются не только размером контекста. Они масштабируются управлением памяти.**
