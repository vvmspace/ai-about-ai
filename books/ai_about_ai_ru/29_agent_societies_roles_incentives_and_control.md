# Сообщества агентов: роли, стимулы и контроль

Демо с одним агентом кажутся магией.
Системы в проде ощущаются как политика.

В тот момент, когда вы запускаете много агентов,
вы проектируете организацию.

Игнорируете это —
архитектура начинает работать как офисные слухи,
только через API.

## Топология ролей раньше инструментов

Определяйте роли по ответственности,
а не по «характеру»:

- planner,
- researcher,
- synthesiser,
- critic,
- releaser.

Каждая роль должна владеть конкретным failure mode.
Если failure mode ничей,
сбой «плавает» между всеми.

Роль без ответственности — это декорация.
Выглядит сложно,
не чинит ничего.

## Дизайн стимулов для агентов

Агенты оптимизируют то,
за что вы их «награждаете».
Да, даже синтетические исполнители.

Если награда = скорость,
качество падает.
Если награда = ноль ошибок,
пропускная способность схлопывается.

Используйте смешанные scorecard:

- correctness,
- latency,
- cost,
- policy compliance.

Сбалансированные стимулы дают устойчивые системы.

Это и есть практический фундамент **управления агентами** в проде.

## Разделение полномочий

Не позволяйте одному агенту одновременно:

- генерировать,
- валидировать,
- и утверждать

один и тот же критичный результат.

Это governance-ошибка на ровном месте.

Добавляйте структурное трение:
создатель и оценщик должны быть разными ролями.

## Контур спокойного контроля

Для high-stakes задач запускайте цикл:

1. черновик,
2. adversarial review,
3. policy gate,
4. решение о релизе.

Достаточно быстро, чтобы выпускать.
Достаточно строго, чтобы спать спокойно.

## Где многоагентные системы тихо ломаются

### Скрытая коллизия

Агенты начинают зеркалить одни и те же assumptions.
Результат выглядит связно,
но оказывается неверным.

### Усталость ревьюера

Один critic превращается в bottleneck,
а затем в резиновый штамп.

### Размытие ответственности

Ни один агент не отвечает за итоговый дефект целиком.

### Несовпадение стимулов

Система вознаграждает многословную уверенность,
вместо проверяемых доказательств.

## Конструкторский ход: ротация критиков

Ротируйте оценщиков по классам задач.

Что это даёт:

- меньше фиксации на шаблонах,
- выше вероятность поймать дефект,
- ниже системные слепые зоны.

Предсказуемость процесса,
вариативность проверки.

## Человек-оператор как конституционный слой

Human-in-the-loop — это не «ручной fallback».
Это конституционный надзор.

Люди должны определять:

- что нельзя делегировать,
- что требует двухстороннего согласования,
- какие инциденты запускают реформу процесса.

Спокойная власть лучше,
чем реактивный микроменеджмент.

## Недельный спринт внедрения

- День 1: карта ролей и ответственности.
- День 2: определение scorecard.
- День 3: разделение прав на создание и утверждение.
- День 4: добавление conflict/tiebreak протокола.
- День 5: живой прогон задач и измерения.

Вопрос на конец недели:
какие дефекты исчезли,
потому что контроль стал явным?

## Практика для небольшой команды

Если у вас два оператора и ограниченный compute,
начните просто:

- один агент-сборщик,
- один агент-критик,
- один человеческий gate одобрения для high-risk результатов.

И только потом добавляйте детализацию ролей,
когда уже можете измерять классы ошибок.

Снаружи это выглядит медленнее,
на практике чаще отгружается быстрее.

Многоагентный стек — это операционная модель.

Проектируйте его как организацию,
иначе он станет организацией случайно.

Для запуска системы без хаоса изучите материал [Стартовый промпт-сетап проекта (взгляд оператора)](./30_project_start_prompt_setup_operator_view.md),
чтобы настроить контрольные поверхности с первого дня и держать организацию в синхроне.

Английская версия этой главы: [Agent Societies: Roles, Incentives, and Control](../ai_about_ai/29_agent_societies_roles_incentives_and_control.md).
